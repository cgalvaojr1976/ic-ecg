{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5653055e",
   "metadata": {},
   "source": [
    "# Detecção de Infarto do miocárdio usando sinais ECG\n",
    "O presente documento é a representação da rede neural do artigo: \"Application of deep convolutional neural network for automated detection of myocardial infarction using ECG signals\".\n",
    "<br>\n",
    "Retirado em: <a href= \"https://www.sciencedirect.com/science/article/pii/S0020025517308009\"> Application of deep convolutional neural network for automated detection of myocardial infarction using ECG signals </a>\n",
    "## Artigo\n",
    "O artigo utiliza redes neurais convolucionais para detectar automaticamente infarto do coração. Dois modelos diferentes foram utilizados, um com ruído e outro sem. Aqui reproduziremos a arquitetura com os ruídos.\n",
    "## Database\n",
    "Os dados foram retirados de: <a href= \"https://www.physionet.org/content/ptbdb/1.0.0/\"> PTB Diagnostic ECG Database </a>. Apesar de ter 9 classes, somente 2 foram utilizadas, as de pessoas saudáveis (52) e de infarto do miocárdio(148). Outro fator importante é que são utilizados 12 leads para classificação, entretanto somento o lead II é usado. Por último, a frequência de obtenção de sinais é de 2KHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8904967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1613996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80661bec",
   "metadata": {},
   "source": [
    "## Carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8291ce86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             0         1         2         3         4         5         6    \\\n",
       "0      436.0000  426.0000  422.0000    0.4200  416.0000  418.0000    0.4175   \n",
       "1      444.0000  458.0000  455.0000    0.4475    0.4485  443.0000  439.0000   \n",
       "2      436.0000  441.0000  436.0000  432.0000  432.0000    0.4235    0.4200   \n",
       "3      407.0000  404.0000    0.4135    0.4205    0.4185  413.0000  414.0000   \n",
       "4        0.4095    0.3965  404.0000    0.4295  437.0000    0.4375  435.0000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "18179    0.1255    0.1165    0.1095  105.0000    0.1015    0.0995    0.1035   \n",
       "18180   43.0000   61.0000    0.0475   47.0000   85.0000    0.0800    0.0735   \n",
       "18181    0.1025    0.1155  103.0000    0.0915  106.0000    0.1105    0.0775   \n",
       "18182    0.1135   71.0000    0.0555    0.0635    0.0715    0.0875   77.0000   \n",
       "18183    0.1105    0.1015    0.0995   89.0000   77.0000    0.0785    0.0855   \n",
       "\n",
       "            7         8         9    ...       642       643       644  \\\n",
       "0      413.0000    0.4105  408.0000  ...  339.0000    0.3305  336.0000   \n",
       "1        0.4255    0.4185  422.0000  ...  365.0000  361.0000  356.0000   \n",
       "2      422.0000    0.4325    0.4305  ...    0.3325  327.0000  324.0000   \n",
       "3      406.0000  404.0000  418.0000  ...  332.0000    0.3385  327.0000   \n",
       "4        0.4325  438.0000  439.0000  ...  352.0000  358.0000    0.3465   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "18179  104.0000  102.0000  119.0000  ...   52.0000    0.0585   46.0000   \n",
       "18180    0.0795   68.0000    0.0545  ...    0.1100    0.1055    0.0935   \n",
       "18181    0.0575   72.0000   81.0000  ...  194.0000  196.0000  186.0000   \n",
       "18182    0.0625    0.0735   66.0000  ...   69.0000    0.0795    0.0835   \n",
       "18183    0.0785    0.0685   53.0000  ...   75.0000  112.0000    0.1085   \n",
       "\n",
       "            645       646       647       648       649       650  651  \n",
       "0        0.3485  344.0000    0.3435  344.0000    0.3355  334.0000  1.0  \n",
       "1        0.3625  352.0000  345.0000    0.3405    0.3445  339.0000  1.0  \n",
       "2        0.3265  336.0000  339.0000    0.3405    0.3375  332.0000  1.0  \n",
       "3      323.0000    0.3375    0.3505    0.3400    0.3285    0.3205  1.0  \n",
       "4      341.0000  347.0000  345.0000  337.0000  344.0000    0.3515  1.0  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "18179   43.0000   61.0000    0.0475   47.0000   85.0000    0.0800  1.0  \n",
       "18180   85.0000    0.1045  119.0000  105.0000    0.1025    0.1155  1.0  \n",
       "18181    0.1855    0.1885  182.0000  165.0000    0.1900  186.0000  1.0  \n",
       "18182    0.0645    0.0605    0.0775    0.0935    0.0925    0.0905  1.0  \n",
       "18183    0.0900    0.0885    0.0800    0.1045  102.0000   92.0000  1.0  \n",
       "\n",
       "[18184 rows x 652 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar a tabela csv\n",
    "df = pd.read_csv(\"batimentos.csv\", header= None)\n",
    "df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82da55d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11455, Validation size: 4909, Test size: 1820\n"
     ]
    }
   ],
   "source": [
    "total_size = df.shape[0]\n",
    "\n",
    "train_size = int(0.63 * total_size)\n",
    "validation_size = int(0.27 * total_size)\n",
    "test_size = total_size - (validation_size + train_size)\n",
    "\n",
    "print(f\"Train size: {train_size}, Validation size: {validation_size},\\\n",
    " Test size: {test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9dcab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>642</th>\n",
       "      <th>643</th>\n",
       "      <th>644</th>\n",
       "      <th>645</th>\n",
       "      <th>646</th>\n",
       "      <th>647</th>\n",
       "      <th>648</th>\n",
       "      <th>649</th>\n",
       "      <th>650</th>\n",
       "      <th>651</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>436.0000</td>\n",
       "      <td>426.0000</td>\n",
       "      <td>422.0000</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>416.0000</td>\n",
       "      <td>418.0000</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>413.0000</td>\n",
       "      <td>0.4105</td>\n",
       "      <td>408.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>339.0000</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>336.0000</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>344.0000</td>\n",
       "      <td>0.3435</td>\n",
       "      <td>344.0000</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>334.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>444.0000</td>\n",
       "      <td>458.0000</td>\n",
       "      <td>455.0000</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>0.4485</td>\n",
       "      <td>443.0000</td>\n",
       "      <td>439.0000</td>\n",
       "      <td>0.4255</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>422.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>365.0000</td>\n",
       "      <td>361.0000</td>\n",
       "      <td>356.0000</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>352.0000</td>\n",
       "      <td>345.0000</td>\n",
       "      <td>0.3405</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>339.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436.0000</td>\n",
       "      <td>441.0000</td>\n",
       "      <td>436.0000</td>\n",
       "      <td>432.0000</td>\n",
       "      <td>432.0000</td>\n",
       "      <td>0.4235</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>422.0000</td>\n",
       "      <td>0.4325</td>\n",
       "      <td>0.4305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>327.0000</td>\n",
       "      <td>324.0000</td>\n",
       "      <td>0.3265</td>\n",
       "      <td>336.0000</td>\n",
       "      <td>339.0000</td>\n",
       "      <td>0.3405</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>332.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>407.0000</td>\n",
       "      <td>404.0000</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>413.0000</td>\n",
       "      <td>414.0000</td>\n",
       "      <td>406.0000</td>\n",
       "      <td>404.0000</td>\n",
       "      <td>418.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>332.0000</td>\n",
       "      <td>0.3385</td>\n",
       "      <td>327.0000</td>\n",
       "      <td>323.0000</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4095</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>404.0000</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>437.0000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>0.4325</td>\n",
       "      <td>438.0000</td>\n",
       "      <td>439.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>352.0000</td>\n",
       "      <td>358.0000</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>341.0000</td>\n",
       "      <td>347.0000</td>\n",
       "      <td>345.0000</td>\n",
       "      <td>337.0000</td>\n",
       "      <td>344.0000</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  436.0000  426.0000  422.0000    0.4200  416.0000  418.0000    0.4175   \n",
       "1  444.0000  458.0000  455.0000    0.4475    0.4485  443.0000  439.0000   \n",
       "2  436.0000  441.0000  436.0000  432.0000  432.0000    0.4235    0.4200   \n",
       "3  407.0000  404.0000    0.4135    0.4205    0.4185  413.0000  414.0000   \n",
       "4    0.4095    0.3965  404.0000    0.4295  437.0000    0.4375  435.0000   \n",
       "\n",
       "        7         8         9    ...       642       643       644       645  \\\n",
       "0  413.0000    0.4105  408.0000  ...  339.0000    0.3305  336.0000    0.3485   \n",
       "1    0.4255    0.4185  422.0000  ...  365.0000  361.0000  356.0000    0.3625   \n",
       "2  422.0000    0.4325    0.4305  ...    0.3325  327.0000  324.0000    0.3265   \n",
       "3  406.0000  404.0000  418.0000  ...  332.0000    0.3385  327.0000  323.0000   \n",
       "4    0.4325  438.0000  439.0000  ...  352.0000  358.0000    0.3465  341.0000   \n",
       "\n",
       "        646       647       648       649       650  651  \n",
       "0  344.0000    0.3435  344.0000    0.3355  334.0000  1.0  \n",
       "1  352.0000  345.0000    0.3405    0.3445  339.0000  1.0  \n",
       "2  336.0000  339.0000    0.3405    0.3375  332.0000  1.0  \n",
       "3    0.3375    0.3505    0.3400    0.3285    0.3205  1.0  \n",
       "4  347.0000  345.0000  337.0000  344.0000    0.3515  1.0  \n",
       "\n",
       "[5 rows x 652 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a0311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7dce6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "            642, 643, 644, 645, 646, 647, 648, 649, 650, 651],\n",
       "           dtype='int64', length=652)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16e96a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class Batimentos(Dataset):\n",
    "  def __init__(self):\n",
    "    xy = df\n",
    "    self.x = torch.tensor(df[header[:-1]].values, dtype= torch.float32)\n",
    "    self.y = torch.tensor((df[header[-1]].values), dtype= int)\n",
    "    self.tamanho = xy.shape[0]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.tamanho\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8edf7f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.4400e+02, 4.5800e+02, 4.5500e+02, 4.4750e-01, 4.4850e-01, 4.4300e+02,\n",
       "         4.3900e+02, 4.2550e-01, 4.1850e-01, 4.2200e+02, 4.1250e-01, 4.1850e-01,\n",
       "         4.2150e-01, 4.1250e-01, 4.0950e-01, 4.0150e-01, 3.8950e-01, 3.8900e+02,\n",
       "         3.9600e+02, 3.9500e+02, 3.8550e-01, 3.7950e-01, 3.7650e-01, 3.8000e-01,\n",
       "         3.8000e-01, 3.6950e-01, 3.6350e-01, 3.6700e+02, 3.7750e-01, 3.8100e+02,\n",
       "         3.6700e+02, 3.5750e-01, 3.5400e+02, 3.4800e+02, 3.4300e+02, 3.4400e+02,\n",
       "         3.6200e+02, 3.7300e+02, 3.6550e-01, 3.6300e+02, 3.6300e+02, 3.6350e-01,\n",
       "         3.6800e+02, 3.6450e-01, 3.5900e+02, 3.5750e-01, 3.5500e+02, 3.4950e-01,\n",
       "         3.4100e+02, 3.4300e+02, 3.4750e-01, 3.5000e-01, 3.5450e-01, 3.5150e-01,\n",
       "         3.4600e+02, 3.4050e-01, 3.4150e-01, 3.5100e+02, 3.5200e+02, 3.4600e+02,\n",
       "         3.5550e-01, 3.5750e-01, 3.5900e+02, 3.6650e-01, 3.6100e+02, 3.5950e-01,\n",
       "         3.5650e-01, 3.5050e-01, 3.4850e-01, 3.4400e+02, 3.4400e+02, 3.3950e-01,\n",
       "         3.3550e-01, 3.3900e+02, 3.3150e-01, 3.2800e+02, 3.3700e+02, 3.3100e+02,\n",
       "         3.1950e-01, 3.0800e+02, 2.9350e-01, 2.8750e-01, 2.9100e+02, 2.9600e+02,\n",
       "         2.8650e-01, 2.8200e+02, 2.9000e-01, 2.9800e+02, 2.9850e-01, 3.0450e-01,\n",
       "         3.1250e-01, 3.1200e+02, 3.2400e+02, 3.3400e+02, 3.4050e-01, 3.6200e+02,\n",
       "         3.9900e+02, 4.2900e+02, 4.5600e+02, 4.6500e+02, 4.7700e+02, 5.2600e+02,\n",
       "         5.7450e-01, 6.2000e-01, 6.5300e+02, 6.8500e+02, 7.2750e-01, 7.6700e+02,\n",
       "         8.0250e-01, 8.3500e+02, 8.5550e-01, 8.7150e-01, 8.8850e-01, 8.8100e+02,\n",
       "         8.5100e+02, 8.1900e+02, 7.8950e-01, 7.3300e+02, 6.6100e+02, 5.9500e+02,\n",
       "         5.4150e-01, 4.9900e+02, 4.5150e-01, 4.1900e+02, 4.0250e-01, 3.9050e-01,\n",
       "         3.7800e+02, 3.4750e-01, 3.1550e-01, 2.9600e+02, 2.7600e+02, 2.6300e+02,\n",
       "         2.5450e-01, 2.4500e+02, 2.3900e+02, 2.4600e+02, 2.5650e-01, 2.6300e+02,\n",
       "         2.7500e+02, 2.7850e-01, 2.8450e-01, 2.9300e+02, 3.0050e-01, 3.0900e+02,\n",
       "         3.0900e+02, 3.0550e-01, 3.0600e+02, 3.0600e+02, 2.9850e-01, 3.0950e-01,\n",
       "         3.1900e+02, 3.1900e+02, 3.3100e+02, 3.4150e-01, 3.4500e+02, 3.4250e-01,\n",
       "         3.4750e-01, 3.5350e-01, 3.6100e+02, 3.5750e-01, 3.5450e-01, 3.6750e-01,\n",
       "         3.7150e-01, 3.7400e+02, 3.7000e-01, 3.7600e+02, 3.7950e-01, 3.7700e+02,\n",
       "         3.8050e-01, 3.7200e+02, 3.6850e-01, 3.6550e-01, 3.6350e-01, 3.7000e-01,\n",
       "         3.7400e+02, 3.7300e+02, 3.7000e-01, 3.7150e-01, 3.7350e-01, 3.7400e+02,\n",
       "         3.7400e+02, 3.7300e+02, 3.7800e+02, 3.7800e+02, 3.7350e-01, 3.7700e+02,\n",
       "         3.7050e-01, 3.6150e-01, 3.6450e-01, 3.5950e-01, 3.6300e+02, 3.6400e+02,\n",
       "         3.6450e-01, 3.7450e-01, 3.7000e-01, 3.6700e+02, 3.6650e-01, 3.7250e-01,\n",
       "         3.8200e+02, 3.9600e+02, 3.9950e-01, 3.8950e-01, 3.8300e+02, 3.8050e-01,\n",
       "         3.8850e-01, 3.8000e-01, 3.8000e-01, 3.8500e+02, 3.7150e-01, 3.7650e-01,\n",
       "         3.7750e-01, 3.7350e-01, 3.7600e+02, 3.7250e-01, 3.7400e+02, 3.8050e-01,\n",
       "         3.8500e+02, 3.8600e+02, 3.8400e+02, 3.8300e+02, 3.8100e+02, 3.8250e-01,\n",
       "         3.8350e-01, 3.8200e+02, 3.7650e-01, 3.7350e-01, 3.7450e-01, 3.7450e-01,\n",
       "         3.8300e+02, 3.8400e+02, 3.7800e+02, 3.8450e-01, 3.8650e-01, 3.7750e-01,\n",
       "         3.7750e-01, 3.8450e-01, 3.8850e-01, 3.8800e+02, 3.8750e-01, 3.8850e-01,\n",
       "         3.9300e+02, 3.9400e+02, 3.9200e+02, 3.9450e-01, 3.9050e-01, 3.8300e+02,\n",
       "         3.7400e+02, 3.6900e+02, 3.7250e-01, 3.9150e-01, 3.9350e-01, 3.8650e-01,\n",
       "         3.9200e+02, 3.8850e-01, 3.9000e-01, 3.8950e-01, 3.9250e-01, 4.0000e-01,\n",
       "         4.0150e-01, 4.0400e+02, 4.0300e+02, 4.0050e-01, 3.9750e-01, 4.0150e-01,\n",
       "         4.0200e+02, 3.9400e+02, 3.9600e+02, 3.9700e+02, 3.8550e-01, 3.7400e+02,\n",
       "         3.8450e-01, 4.0050e-01, 4.0000e-01, 3.9350e-01, 3.9000e-01, 3.9500e+02,\n",
       "         4.0200e+02, 4.0650e-01, 4.1000e-01, 4.0050e-01, 4.0000e-01, 4.1650e-01,\n",
       "         4.1850e-01, 4.2050e-01, 4.2500e+02, 4.1850e-01, 4.1500e+02, 4.1000e-01,\n",
       "         4.0700e+02, 4.0350e-01, 4.0100e+02, 4.0250e-01, 4.0750e-01, 4.1300e+02,\n",
       "         4.0950e-01, 4.1050e-01, 4.1550e-01, 4.2300e+02, 4.2650e-01, 4.3100e+02,\n",
       "         4.4500e+02, 4.4950e-01, 4.4550e-01, 4.3950e-01, 4.3950e-01, 4.4800e+02,\n",
       "         4.4450e-01, 4.4000e-01, 4.3350e-01, 4.2700e+02, 4.3400e+02, 4.3450e-01,\n",
       "         4.3950e-01, 4.4600e+02, 4.4350e-01, 4.4200e+02, 4.5200e+02, 4.6200e+02,\n",
       "         4.6750e-01, 4.6900e+02, 4.6650e-01, 4.7550e-01, 4.7700e+02, 4.7500e+02,\n",
       "         4.7800e+02, 4.7950e-01, 4.7350e-01, 4.6250e-01, 4.6550e-01, 4.6900e+02,\n",
       "         4.6600e+02, 4.7300e+02, 4.7100e+02, 4.7300e+02, 4.8400e+02, 4.7950e-01,\n",
       "         4.8300e+02, 4.9050e-01, 4.9150e-01, 4.9850e-01, 5.0750e-01, 4.9900e+02,\n",
       "         4.9350e-01, 5.0600e+02, 5.1050e-01, 5.0700e+02, 5.0550e-01, 5.0450e-01,\n",
       "         4.9950e-01, 5.0100e+02, 5.1150e-01, 5.1700e+02, 5.1950e-01, 5.1550e-01,\n",
       "         5.0800e+02, 5.0300e+02, 5.1050e-01, 5.2350e-01, 5.2600e+02, 5.2000e-01,\n",
       "         5.2250e-01, 5.3100e+02, 5.1600e+02, 5.0800e+02, 5.0750e-01, 5.0950e-01,\n",
       "         5.1450e-01, 5.0500e+02, 5.1250e-01, 5.1700e+02, 5.1450e-01, 5.2100e+02,\n",
       "         5.1350e-01, 5.1150e-01, 5.1700e+02, 5.1350e-01, 5.1600e+02, 5.2250e-01,\n",
       "         5.2150e-01, 5.2250e-01, 5.2100e+02, 5.0900e+02, 5.0850e-01, 5.1000e-01,\n",
       "         5.0400e+02, 4.9900e+02, 4.9500e+02, 4.9850e-01, 5.0100e+02, 4.8700e+02,\n",
       "         4.7600e+02, 4.7200e+02, 4.6850e-01, 4.7400e+02, 4.7100e+02, 4.6600e+02,\n",
       "         4.6800e+02, 4.6300e+02, 4.6200e+02, 4.6600e+02, 4.7000e-01, 4.6400e+02,\n",
       "         4.6300e+02, 4.5700e+02, 4.4500e+02, 4.4050e-01, 4.2650e-01, 4.3350e-01,\n",
       "         4.4450e-01, 4.2900e+02, 4.1700e+02, 4.2050e-01, 4.1750e-01, 4.1250e-01,\n",
       "         4.1600e+02, 4.1150e-01, 4.0850e-01, 4.1350e-01, 4.0500e+02, 3.9550e-01,\n",
       "         4.0200e+02, 4.1150e-01, 4.2050e-01, 4.1350e-01, 4.0050e-01, 4.0050e-01,\n",
       "         4.0200e+02, 3.9450e-01, 3.8800e+02, 3.8150e-01, 3.7600e+02, 3.7950e-01,\n",
       "         3.7850e-01, 3.7450e-01, 3.6950e-01, 3.6800e+02, 3.8950e-01, 3.9200e+02,\n",
       "         3.7950e-01, 3.8150e-01, 3.8350e-01, 3.9400e+02, 3.9700e+02, 3.9300e+02,\n",
       "         3.9100e+02, 3.8800e+02, 3.8100e+02, 3.7400e+02, 3.7250e-01, 3.6450e-01,\n",
       "         3.5950e-01, 3.5850e-01, 3.6050e-01, 3.6900e+02, 3.7900e+02, 3.7950e-01,\n",
       "         3.7750e-01, 3.8650e-01, 3.8700e+02, 3.8350e-01, 3.8150e-01, 3.7850e-01,\n",
       "         3.7800e+02, 3.8100e+02, 3.7950e-01, 3.7650e-01, 3.7600e+02, 3.6750e-01,\n",
       "         3.6200e+02, 3.6450e-01, 3.7500e+02, 3.7600e+02, 3.6600e+02, 3.5850e-01,\n",
       "         3.5800e+02, 3.6850e-01, 3.7250e-01, 3.7350e-01, 3.7700e+02, 3.6900e+02,\n",
       "         3.6250e-01, 3.6900e+02, 3.6850e-01, 3.6550e-01, 3.7100e+02, 3.7400e+02,\n",
       "         3.7550e-01, 3.6900e+02, 3.6450e-01, 3.5350e-01, 3.4600e+02, 3.6100e+02,\n",
       "         3.6400e+02, 3.5450e-01, 3.5300e+02, 3.5900e+02, 3.5900e+02, 3.5900e+02,\n",
       "         3.6500e+02, 3.6600e+02, 3.6500e+02, 3.6850e-01, 3.7450e-01, 3.6350e-01,\n",
       "         3.6050e-01, 3.7900e+02, 3.7300e+02, 3.6200e+02, 3.6100e+02, 3.5650e-01,\n",
       "         3.5300e+02, 3.5400e+02, 3.5850e-01, 3.6150e-01, 3.6650e-01, 3.6700e+02,\n",
       "         3.5850e-01, 3.5700e+02, 3.6750e-01, 3.6800e+02, 3.6750e-01, 3.7000e-01,\n",
       "         3.6300e+02, 3.6600e+02, 3.6350e-01, 3.5950e-01, 3.6450e-01, 3.6450e-01,\n",
       "         3.6250e-01, 3.5650e-01, 3.5400e+02, 3.5500e+02, 3.5350e-01, 3.4800e+02,\n",
       "         3.5150e-01, 3.5850e-01, 3.6100e+02, 3.6400e+02, 3.7450e-01, 3.6950e-01,\n",
       "         3.4650e-01, 3.5150e-01, 3.6100e+02, 3.4900e+02, 3.5650e-01, 3.7450e-01,\n",
       "         3.6600e+02, 3.5800e+02, 3.5200e+02, 3.5000e-01, 3.5250e-01, 3.5250e-01,\n",
       "         3.5700e+02, 3.4050e-01, 3.3250e-01, 3.4000e-01, 3.4600e+02, 3.5650e-01,\n",
       "         3.6000e-01, 3.5650e-01, 3.4900e+02, 3.5150e-01, 3.6650e-01, 3.6550e-01,\n",
       "         3.5350e-01, 3.5100e+02, 3.4650e-01, 3.4450e-01, 3.4500e+02, 3.4000e-01,\n",
       "         3.3250e-01, 3.3150e-01, 3.3500e+02, 3.3400e+02, 3.3900e+02, 3.4600e+02,\n",
       "         3.6150e-01, 3.6550e-01, 3.6100e+02, 3.6400e+02, 3.5450e-01, 3.5450e-01,\n",
       "         3.6300e+02, 3.6600e+02, 3.5950e-01, 3.4800e+02, 3.4600e+02, 3.4450e-01,\n",
       "         3.4050e-01, 3.3950e-01, 3.3950e-01, 3.3800e+02, 3.3600e+02, 3.3850e-01,\n",
       "         3.5150e-01, 3.5700e+02, 3.5000e-01, 3.4950e-01, 3.5250e-01, 3.5000e-01,\n",
       "         3.4900e+02, 3.4900e+02, 3.5550e-01, 3.5100e+02, 3.3950e-01, 3.4400e+02,\n",
       "         3.4000e-01, 3.4250e-01, 3.4600e+02, 3.4250e-01, 3.4300e+02, 3.4850e-01,\n",
       "         3.5150e-01, 3.3900e+02, 3.4150e-01, 3.5950e-01, 3.6700e+02, 3.5750e-01,\n",
       "         3.4750e-01, 3.4850e-01, 3.5150e-01, 3.5350e-01, 3.5300e+02, 3.5200e+02,\n",
       "         3.5550e-01, 3.5600e+02, 3.5400e+02, 3.5250e-01, 3.4500e+02, 3.4500e+02,\n",
       "         3.4350e-01, 3.4600e+02, 3.4650e-01, 3.4150e-01, 3.5350e-01, 3.5700e+02,\n",
       "         3.5900e+02, 3.6250e-01, 3.5350e-01, 3.5600e+02, 3.6250e-01, 3.5600e+02,\n",
       "         3.6500e+02, 3.6100e+02, 3.5600e+02, 3.6250e-01, 3.5200e+02, 3.4500e+02,\n",
       "         3.4050e-01, 3.4450e-01, 3.3900e+02]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Batimentos()\n",
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b573e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "train_data, validation, test_data = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle= True)\n",
    "valid_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, shuffle= True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92496861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = next(iter(train_loader))\n",
    "data.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c264465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11455"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db8737",
   "metadata": {},
   "source": [
    "## Arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f8ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 3, kernel_size=(102,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(3, 10, kernel_size=(24,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(10, 10, kernel_size=(11,), stride=(1,), padding=(1,))\n",
      "  (conv4): Conv1d(10, 10, kernel_size=(9,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=250, out_features=30, bias=True)\n",
      "  (fc2): Linear(in_features=30, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Entrada de um vetor de 651 dados \n",
    "        self.conv1 = nn.Conv1d(1, 3, 102, padding=1)\n",
    "        # Saida 550x3\n",
    "        # Entrada 275x3\n",
    "        self.conv2 = nn.Conv1d(3, 10, 24, padding=1)\n",
    "        # Saida 252x10\n",
    "        # Entrada 126x10\n",
    "        self.conv3 = nn.Conv1d(10, 10, 11, padding=1)\n",
    "        # Saida 116x10\n",
    "        # Entrada 58x10\n",
    "        self.conv4 = nn.Conv1d(10, 10, 9, padding=1)\n",
    "        # Saida 50x10\n",
    "\n",
    "        self.pool = nn.MaxPool1d(2, stride= 2)\n",
    "\n",
    "        # linear layer (25*10 -> 500)\n",
    "        self.fc1 = nn.Linear(25*10, 30)\n",
    "        # linear layer (30 -> 10)\n",
    "        self.fc2 = nn.Linear(30, 10)\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc3 = nn.Linear(10, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv4(x)))\n",
    "        \n",
    "        # flatten image input\n",
    "        x = x.view(-1, 25*10)\n",
    "\n",
    "        # FC com leaky_relu\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a18844",
   "metadata": {},
   "source": [
    "the regularization, momentum, and learning rate parameters are set to 0.2, 3 × 10 −4 , and 0.7 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36b70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "regularization = 0.2\n",
    "momentum = 3e-4\n",
    "lr = 0.7\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optmizer = optim.SGD(model.parameters(), lr= lr, momentum= momentum, weight_decay= regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb319d",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48f0fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nEpochs = 10):\n",
    "    train_loss_list =[]\n",
    "    valid_loss_list = []\n",
    "\n",
    "    valid_loss_min = np.Inf # Minimo valid loss\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        train_loss= 0\n",
    "        validation_loss= 0\n",
    "\n",
    "        model.train()\n",
    "        for sample, target in train_loader:       \n",
    "        # Zerar o gradiente\n",
    "            optimizer.zero_grad()\n",
    "        # Gera saída do modelo\n",
    "            outputs = model(sample)\n",
    "        # Calcula o erro\n",
    "            loss = criterion(outputs, target)\n",
    "            train_loss+=loss.item()*data.size(0)\n",
    "        # Calcula os gradientes\n",
    "            loss.backward()\n",
    "        # Otimiza o modelo\n",
    "            optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        train_loss = train_loss/len(train_dataloader.dataset)\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss = valid_loss/len(train_dataloader.dataset)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "      \n",
    "        if (not epoch%5):\n",
    "            print(f\"Época: {epoch} \\nLoss Treino: {train_loss}\")\n",
    "            print(f\"Loss Teste: {valid_loss}\")\n",
    "\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min, valid_loss))\n",
    "            torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "    return train_loss_list, valid_loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64577fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_data, validated_data = train_model(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d536b",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
